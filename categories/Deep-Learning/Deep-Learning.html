<!DOCTYPE html><html><head>
      <title>Deep Learning</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css">
      
      
      
      
      
      
      
      
      
      <style>
      /**
 * prism.js Github theme based on GitHub's theme.
 * @author Sam Clarke
 */
code[class*="language-"],
pre[class*="language-"] {
  color: #333;
  background: none;
  font-family: Consolas, "Liberation Mono", Menlo, Courier, monospace;
  text-align: left;
  white-space: pre;
  word-spacing: normal;
  word-break: normal;
  word-wrap: normal;
  line-height: 1.4;

  -moz-tab-size: 8;
  -o-tab-size: 8;
  tab-size: 8;

  -webkit-hyphens: none;
  -moz-hyphens: none;
  -ms-hyphens: none;
  hyphens: none;
}

/* Code blocks */
pre[class*="language-"] {
  padding: .8em;
  overflow: auto;
  /* border: 1px solid #ddd; */
  border-radius: 3px;
  /* background: #fff; */
  background: #f5f5f5;
}

/* Inline code */
:not(pre) > code[class*="language-"] {
  padding: .1em;
  border-radius: .3em;
  white-space: normal;
  background: #f5f5f5;
}

.token.comment,
.token.blockquote {
  color: #969896;
}

.token.cdata {
  color: #183691;
}

.token.doctype,
.token.punctuation,
.token.variable,
.token.macro.property {
  color: #333;
}

.token.operator,
.token.important,
.token.keyword,
.token.rule,
.token.builtin {
  color: #a71d5d;
}

.token.string,
.token.url,
.token.regex,
.token.attr-value {
  color: #183691;
}

.token.property,
.token.number,
.token.boolean,
.token.entity,
.token.atrule,
.token.constant,
.token.symbol,
.token.command,
.token.code {
  color: #0086b3;
}

.token.tag,
.token.selector,
.token.prolog {
  color: #63a35c;
}

.token.function,
.token.namespace,
.token.pseudo-element,
.token.class,
.token.class-name,
.token.pseudo-class,
.token.id,
.token.url-reference .token.variable,
.token.attr-name {
  color: #795da3;
}

.token.entity {
  cursor: help;
}

.token.title,
.token.title .token.punctuation {
  font-weight: bold;
  color: #1d3e81;
}

.token.list {
  color: #ed6a43;
}

.token.inserted {
  background-color: #eaffea;
  color: #55a532;
}

.token.deleted {
  background-color: #ffecec;
  color: #bd2c00;
}

.token.bold {
  font-weight: bold;
}

.token.italic {
  font-style: italic;
}


/* JSON */
.language-json .token.property {
  color: #183691;
}

.language-markup .token.tag .token.punctuation {
  color: #333;
}

/* CSS */
code.language-css,
.language-css .token.function {
  color: #0086b3;
}

/* YAML */
.language-yaml .token.atrule {
  color: #63a35c;
}

code.language-yaml {
  color: #183691;
}

/* Ruby */
.language-ruby .token.function {
  color: #333;
}

/* Markdown */
.language-markdown .token.url {
  color: #795da3;
}

/* Makefile */
.language-makefile .token.symbol {
  color: #795da3;
}

.language-makefile .token.variable {
  color: #183691;
}

.language-makefile .token.builtin {
  color: #0086b3;
}

/* Bash */
.language-bash .token.keyword {
  color: #0086b3;
}

/* highlight */
pre[data-line] {
  position: relative;
  padding: 1em 0 1em 3em;
}
pre[data-line] .line-highlight-wrapper {
  position: absolute;
  top: 0;
  left: 0;
  background-color: transparent;
  display: block;
  width: 100%;
}

pre[data-line] .line-highlight {
  position: absolute;
  left: 0;
  right: 0;
  padding: inherit 0;
  margin-top: 1em;
  background: hsla(24, 20%, 50%,.08);
  background: linear-gradient(to right, hsla(24, 20%, 50%,.1) 70%, hsla(24, 20%, 50%,0));
  pointer-events: none;
  line-height: inherit;
  white-space: pre;
}

pre[data-line] .line-highlight:before, 
pre[data-line] .line-highlight[data-end]:after {
  content: attr(data-start);
  position: absolute;
  top: .4em;
  left: .6em;
  min-width: 1em;
  padding: 0 .5em;
  background-color: hsla(24, 20%, 50%,.4);
  color: hsl(24, 20%, 95%);
  font: bold 65%/1.5 sans-serif;
  text-align: center;
  vertical-align: .3em;
  border-radius: 999px;
  text-shadow: none;
  box-shadow: 0 1px white;
}

pre[data-line] .line-highlight[data-end]:after {
  content: attr(data-end);
  top: auto;
  bottom: .4em;
}html body{font-family:"Helvetica Neue",Helvetica,"Segoe UI",Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ul,html body>ol{margin-bottom:16px}html body ul,html body ol{padding-left:2em}html body ul.no-list,html body ol.no-list{padding:0;list-style-type:none}html body ul ul,html body ul ol,html body ol ol,html body ol ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;background-color:#f0f0f0;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:bold;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:bold}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em !important;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::before,html body code::after{letter-spacing:-0.2em;content:"\00a0"}html body pre>code{padding:0;margin:0;font-size:.85em !important;word-break:normal;white-space:pre;background:transparent;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;font-size:.85em !important;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:before,html body pre tt:before,html body pre code:after,html body pre tt:after{content:normal}html body p,html body blockquote,html body ul,html body ol,html body dl,html body pre{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body pre,html body code{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview .pagebreak,.markdown-preview .newpage{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center !important}.markdown-preview:not([for="preview"]) .code-chunk .btn-group{display:none}.markdown-preview:not([for="preview"]) .code-chunk .status{display:none}.markdown-preview:not([for="preview"]) .code-chunk .output-div{margin-bottom:16px}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0}@media screen and (min-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px + 2em)}}@media screen and (max-width:914px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode]) .markdown-preview{font-size:14px !important;padding:1em}}@media print{html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for="html-export"]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,0.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,0.66);border:4px solid rgba(150,150,150,0.66);background-clip:content-box}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc ul{padding:0 1.6em;margin-top:.8em}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc li{margin-bottom:.8em}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc ul{list-style-type:none}html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% -  300px);padding:2em calc(50% - 457px -  150px);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for="html-export"]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for="html-export"]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */
.markdown-preview.markdown-preview {
  /* PICK ONE */
  /* don't expand nested items, which pushes down the rest of the page when navigating */
  /* Effect 3: bottom line slides/fades in */
}
@font-face {
  font-family: 'Open Sans';
  font-style: italic;
  font-weight: 400;
  src: url(https://fonts.gstatic.com/s/opensans/v18/mem6YaGs126MiZpBA-UFUK0Zdcg.ttf) format('truetype');
}
.markdown-preview.markdown-preview body {
  padding: 7vh;
}
.markdown-preview.markdown-preview ol.toc-list {
  font-size: x-small;
}
.markdown-preview.markdown-preview #toc a {
  color: #47404e;
}
.markdown-preview.markdown-preview h1,
.markdown-preview.markdown-preview h2,
.markdown-preview.markdown-preview h3 {
  padding-top: 1rem;
  padding-bottom: 1rem;
}
.markdown-preview.markdown-preview blockquote {
  margin: 50px auto;
  font-style: italic;
  color: #555555;
  padding: 1.2em 30px 1.2em 75px;
  border-left: 8px solid #47404e;
  line-height: 1.6;
  position: relative;
  background: #ededed;
}
.markdown-preview.markdown-preview blockquote::before {
  font-family: Arial;
  content: "\201C";
  color: #47404e;
  font-size: 4em;
  position: absolute;
  left: 10px;
  top: -10px;
}
.markdown-preview.markdown-preview blockquote::after {
  content: "";
}
.markdown-preview.markdown-preview .bs-example {
  position: relative;
  padding: 45px 15px 15px;
  margin: 0 -15px 15px;
  border-color: #e5e5e5 #eee #eee;
  border-style: solid;
  border-width: 1px 0;
  box-shadow: inset 0 3px 6px rgba(0, 0, 0, 0.05);
}
.markdown-preview.markdown-preview .bs-example:after {
  position: absolute;
  top: 15px;
  left: 15px;
  font-size: 12px;
  font-weight: 700;
  color: #959595;
  text-transform: uppercase;
  letter-spacing: 1px;
  content: "Example";
}
.markdown-preview.markdown-preview .panel-heading {
  -webkit-tap-highlight-color: transparent;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  font-size: 0.75rem;
  line-height: 1.42857143;
  box-sizing: border-box;
  height: 3vh;
  padding-bottom: 5vw;
  border-bottom: 0.2vh solid transparent;
  border-top-left-radius: 3px;
  border-top-right-radius: 3px;
  color: #333;
  background-color: #f5f5f5;
  border-color: #ddd;
}
.markdown-preview.markdown-preview .panel-body {
  -webkit-tap-highlight-color: transparent;
  font-family: "Helvetica Neue", Helvetica, Arial, sans-serif;
  line-height: 1.42857143;
  color: #333;
  box-sizing: border-box;
  padding: 15px;
}
.markdown-preview.markdown-preview div.panel-heading > h5 {
  padding-left: 1vw;
  padding-top: 1vh;
  font-size: 1.5rem;
}
.markdown-preview.markdown-preview img {
  width: 100%;
  height: auto;
}
.markdown-preview.markdown-preview .img-row img {
  height: 30vh;
}
.markdown-preview.markdown-preview a.is-active-link::before {
  background-color: #47404e;
}
.markdown-preview.markdown-preview nav[data-toggle="toc"] {
  top: 42px;
}
.markdown-preview.markdown-preview nav[data-toggle="toc"] .nav .active .nav {
  display: none;
}
.markdown-preview.markdown-preview .keyword1 {
  color: #c25c5c;
  font-weight: bold;
}
.markdown-preview.markdown-preview .keyword2 {
  color: #2e7caa;
  font-weight: bold;
}
.markdown-preview.markdown-preview .keyword3 {
  color: #709925;
  font-weight: bold;
}
.markdown-preview.markdown-preview a {
  color: #b17f7f;
}
.markdown-preview.markdown-preview a:hover {
  text-decoration: none;
  color: #47404e;
  font-weight: bold;
}
.markdown-preview.markdown-preview .navbar a {
  color: #47404e;
}
.markdown-preview.markdown-preview body > div.mume.markdown-preview {
  padding: 3vw;
}

      </style>
    </head>
    <body for="html-export">
      <div class="mume markdown-preview  ">
      



<link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.11.1/tocbot.css">    <link type="text/css" rel="stylesheet" href="../../static/assets/styles/style.css">    <div class="container">              <div class="row">                        <div class="col-3">                <nav id="toc" data-toggle="toc" class="sticky-top toc"></nav>            </div>                 <div class="col-9 content">

<div class="navbar"></div><div class="note-content">

<h1 class="mume-header" id="ai-vs-ml-vs-dl">AI vs. ML vs. DL</h1>

<p><img src="https://www.kdnuggets.com/wp-content/uploads/ai-machine-learning-deep-learning-1.jpg" alt="AI vs ML vs DL"></p>
<dl>
    <dt>AI</dt>
    <dd>Classical Programming - The human inputs code which let&apos;s computers do tasks for us</dd>
    <dt>Machine Learning</dt>
    <dd>Humans clean up some data, feed it to the model, and the model creates it&apos;s own rules.  Trained, not explicitly programmed.</dd>
    <dt>Deep Learning</dt>
    <dd></dd>
</dl>
<h2 class="mume-header" id="ml-requirements">ML Requirements</h2>

<ul>
<li>Inputs - sound files</li>
<li>Labels - transcripts</li>
<li>Scoring metrics - used to adjust the model as it learns</li>
</ul>
<h2 class="mume-header" id="deep-learning">Deep Learning</h2>

<p>Here, we define <em>our own representations</em> of data in multiple layers.  Layers are assigned weights, which are constantly optimized based on the <strong>loss function</strong></p>
<p><img src="../../static/assets/media/Deep-Learning-Diagram.png" alt="Deep-Learning-Diagram"></p>
<h2 class="mume-header" id="ml-or-dl">ML or DL?</h2>

<p>Don&apos;t start using deep learning for every problem.  That&apos;s using a jackhammer to floss rabbit teeth.</p>
<p>For complex problems, here are the advantage of DL:</p>
<ul>
<li>Removes feature engineering</li>
<li><strong>Adjusts everything</strong> at once rather than one weak model at a time, as high-performing ML algorithms like XGBoost do.</li>
</ul>
<h2 class="mume-header" id="practical-mldl">Practical ML/DL</h2>

<p>Learn XGBoost and Keras.  Watch the Kaggle competitions to stay up-to-date.  Win.</p>
<h1 class="mume-header" id="neural-network-basics">Neural Network Basics</h1>

<p>What steps should we take to build a neural network with Keras?</p>
<h2 class="mume-header" id="split">Split</h2>

<p>First, we have to decide our data into features and labels.  A dimension check never hurts anyone, using the <code>.shape</code> attribute.</p>
<p>Don&apos;t forget to use a <code>reshape(-1, 1)</code> to get the proper <strong>column vector</strong> for the labels.  For example, if we have a table of 4 features and 10 samples (10, 4), then the shape of our labels should be (10, 1).</p>
<h2 class="mume-header" id="sculpt">Sculpt</h2>

<p>This step involves:</p>
<ul>
<li>Instantiate the model - for example, run <code>models.Sequential()</code>, and put that in a <code>network</code> variable.</li>
<li>Add layers with <code>.add(layers)</code></li>
</ul>
<h2 class="mume-header" id="compile">Compile</h2>

<p>To make our network ready for training, we need three things:</p>
<ul>
<li>Loss function</li>
<li>Optimizer</li>
<li>Scoring metrics</li>
</ul>
<p>Pass these to <code>network.compile()</code> as <code>**kwargs</code>, and we&apos;re on our way!</p>
<h2 class="mume-header" id="preprocess">Preprocess</h2>

<h3 class="mume-header" id="reshaping">Reshaping</h3>

<p>The training images from the MNIST dataset are of shape (60000, 28, 28).  How do we make this <em>usable</em> for Keras?</p>
<pre data-role="codeBlock" data-info="python" class="language-python">train_images <span class="token operator">=</span> train_imags<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">60000</span><span class="token punctuation">,</span> <span class="token number">28</span><span class="token operator">*</span><span class="token number">28</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</pre><p>With multi-dimensional shapes, the <code>reshape</code> must have the same <strong>product</strong> as the original shape.</p>
<h3 class="mume-header" id="datatype-check">DataType Check</h3>

<p>Just like with machine learning, we need <em>numbers</em>.  A quick <code>.astype(&apos;float32&apos;)</code> can do wonders.</p>
<h3 class="mume-header" id="standardization">Standardization</h3>

<p>If our interval is [0, 255], we just divide the data by 255 so it&apos;s in the range [0, 1].</p>
<p>If necessary, you can always use Sci-Kit&apos;s toolbox.</p>
<h3 class="mume-header" id="categorical-types">Categorical Types</h3>

<p>Keras makes this easier for us than other libraries.  Rather than one hot encoding, just use the <code>to_categorical(data)</code> function from the <code>keras.utils</code> module.</p>
<h2 class="mume-header" id="train">Train!</h2>

<p>Use the <code>.fit(training_data, training_labels)</code> function on the network, and be exposed to the wonders of Deep Learning!</p>
<h1 class="mume-header" id="tensor-manipulation">Tensor Manipulation</h1>

<p>Ahh, tensors, arrays of matrices (or tensors . . .).  How do we work with them?</p>
<h2 class="mume-header" id="slicing">Slicing</h2>

<p>Slicing tensors is just like slicing numpy matrices.  You can even use shorthand.</p>
<pre data-role="codeBlock" data-info="python" class="language-python"><span class="token comment"># This </span>
train_images<span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">:</span><span class="token number">100</span><span class="token punctuation">]</span>

<span class="token comment"># Is equivalent to this </span>
train_images<span class="token punctuation">[</span><span class="token number">10</span><span class="token punctuation">:</span><span class="token number">100</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">,</span> <span class="token punctuation">:</span><span class="token punctuation">]</span>
</pre><h2 class="mume-header" id="batches">Batches</h2>

<p>We know the samples axis and axis = 0 are equivalent.  But, with neural networks, we&apos;re constantly subdividing data into simpler parts.</p>
<p>In batches, axis 0 is the <strong>batch axis</strong>.</p>
<h2 class="mume-header" id="common-dimensions">Common dimensions</h2>

<ul>
<li>2D - Vectors
<ul>
<li>Tables - Bank represents everyone as a name, income, and zip code.  If we have 100,000 people, our shape would be (100000, 3)</li>
</ul>
</li>
<li>3D - Timeseries or Sequences
<ul>
<li>Stock data has samples, features, and time attributes</li>
</ul>
</li>
<li>4D - Image Data
<ul>
<li>Samples, height, width, color-depth</li>
</ul>
</li>
<li>5D - Video
<ul>
<li>Image data with the extra frames dimension</li>
</ul>
</li>
</ul>
<h2 class="mume-header" id="operations">Operations</h2>

<h3 class="mume-header" id="elementwise">Elementwise</h3>

<p>Let&apos;s look at the sculpting process to understand elementwise operations.</p>
<pre data-role="codeBlock" data-info="python" class="language-python">keras<span class="token punctuation">.</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">512</span><span class="token punctuation">,</span> activation <span class="token operator">=</span> <span class="token string">&apos;relu&apos;</span><span class="token punctuation">)</span>
</pre><p>Here, 512 represents the <em>neuron units</em> in our network.  <code>activation</code> is the function which takes an input 2D tensor and outputs another 2D tensor.</p>
<pre data-role="codeBlock" data-info="python" class="language-python">output <span class="token operator">=</span> relu<span class="token punctuation">(</span>dot<span class="token punctuation">(</span>W<span class="token punctuation">,</span> <span class="token builtin">input</span><span class="token punctuation">)</span> <span class="token operator">+</span> b<span class="token punctuation">)</span>
</pre><p>There are a few things going on here.</p>
<ul>
<li><code>dot</code> - dot product</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi></mrow><annotation encoding="application/x-tex">W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">W</span></span></span></span> - The kernel</li>
<li><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">b</span></span></span></span> - The bias</li>
</ul>
<p>The kernel, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi></mrow><annotation encoding="application/x-tex">W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">W</span></span></span></span>, and the bias, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.69444em;vertical-align:0em;"></span><span class="mord mathdefault">b</span></span></span></span>, are known as the <em>weights</em>, or <em>trainable parameters</em> of the layer</p>
<p><img src="https://miro.medium.com/max/467/0*ObwPPSgUtgUqhJtY.png" alt="The Loss Function"></p>
<h3 class="mume-header" id="broadcasting">Broadcasting</h3>

<p>Here&apos;s a <a href="https://deeplizard.com/learn/video/6_33ulFDuCg">helpful video</a>, and my summary.</p>
<p>First, we ask:  Are the dimensions compatabile?</p>
<p>Conditions:</p>
<ul>
<li>Dimensions are equal - (1, 3) and (1, 3)</li>
<li>One of the dimensions is 1 - (1, 5, 3) and (5, 5, 3)</li>
</ul>
<p>The <strong>resultant shape</strong> of a broadcasting operation takes the <em>maximum</em> of the compared dimensions.</p>
<p>Consider (1, 3) and (3, 1).  The resultant shape would be (3, 3)</p>
<h4 class="mume-header" id="mental-model">Mental Model</h4>

<p>The easiest way to picture broadcasting ops is imagining the smaller rank tensor being <em>copied out</em>.  Then, the operation is performed.</p>
<h3 class="mume-header" id="dot-product">Dot Product</h3>

<p>The <code>dot</code> operation differs from <code>*</code>.</p>
<p><img src="https://www.mathsisfun.com/algebra/images/matrix-multiply-a.svg" alt="Dot Product"></p>
<p>My steps:</p>
<ul>
<li>Transpose the first matrix</li>
<li>Multiply column by column</li>
<li>Add up that sum</li>
</ul>
<p>That&apos;s worded a bit different than other explanations, but I like the transposition idea.</p>
<p>Here&apos;s a <a href="https://www.mathsisfun.com/algebra/matrix-multiplying.html">simple explanation</a>.  If you think about matrix multiplication (the dot product) in terms of economics, costs and demand, it&apos;s facile to grasp the logic.</p>
<h4 class="mume-header" id="requirements">Requirements</h4>

<p>Columns of the first matrix must equal the rows of th second.</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>c</mi><mi>x</mi></msub><mo>=</mo><msub><mi>r</mi><mi>y</mi></msub></mrow><annotation encoding="application/x-tex">c_x = r_y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="mord"><span class="mord mathdefault">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">x</span></span></span></span><span class="vlist-s">&#x200B;</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.716668em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span></span></span></span><span class="vlist-s">&#x200B;</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<p>The final output is flipped, so to speak.  The matrix will have the same amount of rows as the first matrix, and the same amount of columns as the second</p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>&#x2217;</mo><mi>y</mi><mo>=</mo><mtext>A&#xA0;matrix&#xA0;of&#xA0;dimensions&#xA0;</mtext><msub><mi>r</mi><mi>x</mi></msub><mtext>and&#xA0;</mtext><msub><mi>c</mi><mi>y</mi></msub></mrow><annotation encoding="application/x-tex">x * y = \text{A matrix of dimensions }r_x \text{and }c_y</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.46528em;vertical-align:0em;"></span><span class="mord mathdefault">x</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">&#x2217;</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.19444em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:0.980548em;vertical-align:-0.286108em;"></span><span class="mord text"><span class="mord">A&#xA0;matrix&#xA0;of&#xA0;dimensions&#xA0;</span></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">x</span></span></span></span><span class="vlist-s">&#x200B;</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord text"><span class="mord">and&#xA0;</span></span><span class="mord"><span class="mord mathdefault">c</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-left:0em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span></span></span></span><span class="vlist-s">&#x200B;</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span></span></span></span></span></p>
<p><img src="../../static/assets/media/DotMap.png" alt="Dot Product Requirements Mapping Image"></p>
<h1 class="mume-header" id="gradient-optimization">Gradient Optimization</h1>

<p>The key to minimizing the loss function is calculating it&apos;s gradient.</p>
<p>Here&apos;s a simple gradient.</p>
<p><img src="https://miro.medium.com/max/640/0*cky02gQU_1I8WdlX.png" alt="Gradient"></p>
<p>Now, one with more features.</p>
<p><img src="https://miro.medium.com/max/631/0*7QToqMHqNhBpuF-U.png" alt="Advanced Gradient"></p>
<p>Either way, we&apos;re interested in the <em>absolute minimum</em>, where the slope = 0.</p>
<h2 class="mume-header" id="batch-sgd">Batch SGD</h2>

<p>An <em>analytical</em> approach is equivalent to actually calculating the derivative of the function.  That&apos;s <em>possible</em>, but extremely taxing on the computer when the number of parameters, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.10903em;">N</span></span></span></span>, goes up.</p>
<p>Instead, we use <strong>SGD</strong> on each batch.  We iterativly tweak the parameters until we hit that sweet spot.</p>
<p><img src="../../static/assets/media/SGD.png" alt="Batch SGD"></p>
<h3 class="mume-header" id="momentum">Momentum</h3>

<p>We have a local/global minimum issue with this approach.</p>
<p><img src="../../static/assets/media/MomentumFixesThis.png" alt="Momentum Fixes This"></p>
<p>To remedy this, we calculate velocities at each step and use the slope, so it won&apos;t stop at each little bump.</p>
<h1 class="mume-header" id="neural-anatomy">Neural Anatomy</h1>

<h2 class="mume-header" id="components">Components</h2>

<p>Let&apos;s dive deeper into the components of neural networks we&apos;ve covered so far:</p>
<ul>
<li>Layers</li>
<li>Input Data</li>
<li>Loss Function</li>
<li>Optimizer</li>
</ul>
<p><img src="../../static/assets/media/NNComp.png" alt="Components"></p>
<p>Additionally, let&apos;s cover:</p>
<ul>
<li>Hidden units</li>
</ul>
<h2 class="mume-header" id="layers">Layers</h2>

<p>Layer types are defined by the shape of the tensors they can take:</p>
<ul>
<li>Dense - 2D Vectors</li>
<li>Recurrent, <code>LSTM</code> - 3D</li>
<li>2D Convolution, <code>Conv2D</code> - 4D</li>
</ul>
<p>The input to one layer is the output of one before it.  This means you only have to specify the input shape of the <strong>first layer</strong>.</p>
<pre data-role="codeBlock" data-info="python" class="language-python"><span class="token keyword">from</span> keras <span class="token keyword">import</span> models
<span class="token keyword">from</span> keras <span class="token keyword">import</span> layers
model <span class="token operator">=</span> models<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> input_shape<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">784</span><span class="token punctuation">,</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span>add<span class="token punctuation">(</span>layers<span class="token punctuation">.</span>Dense<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</pre><h3 class="mume-header" id="dense">Dense</h3>

<p>Linear stacks of layers, the simplest setup we can create.  Luckily, it&apos;s also the <em>most common</em>.  The questions we must ask ourselves are as follows:</p>
<ul>
<li>How many layers?</li>
<li>How many hidden units?</li>
</ul>
<h2 class="mume-header" id="loss-function">Loss Function</h2>

<p>Be <em>very specific</em> in how you define these.  I love the author&apos;s example here:</p>
<blockquote>
<p>Imagine a stupid, omnipotent AI trained via SGD, with this poorly chosen objective function: &quot;maximize the average well-being of all living humans.&quot;  To make its job easier, this AI might choose to kill all humans except a few and focus on the well-being of the remaining ones.</p>
</blockquote>
<p>Choosing a loss function is generally not <em>too</em> difficult.  Here are some common cases:</p>
<ul>
<li>Binary crossentropy - two-class classification</li>
<li>Categorical crossentropy - multi-class classifation</li>
<li>MSE - regression</li>
<li>Connectionist temporal classifcation (CTC) - sequence learning problems</li>
</ul>
<h2 class="mume-header" id="optimizers">Optimizers</h2>

<p>First, we need to understand the <a href="https://towardsdatascience.com/the-vanishing-exploding-gradient-problem-in-deep-neural-networks-191358470c11">exploding/vanishing problem</a> in deep learning.</p>
<h3 class="mume-header" id="explodingvanishing">Exploding/Vanishing</h3>

<p>Detect an explosion problem if you see these signs:</p>
<ul>
<li>Immensely large changes in loss on each step</li>
<li>The model&apos;s loss will be NaN during training</li>
<li>Weights grow exponentially, trending towards <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">&#x221E;</mi></mrow><annotation encoding="application/x-tex">\infin</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.43056em;vertical-align:0em;"></span><span class="mord">&#x221E;</span></span></span></span> and becoming NaN</li>
</ul>
<p>In contrast, vanishing might cause:</p>
<ul>
<li>Immensely small changes in loss on each step</li>
<li>Weights close to the output layer will change more than those close to the input layer</li>
<li>Models shrink exponentially, trending towards 0</li>
</ul>
<h3 class="mume-header" id="rmsprop">rmsprop</h3>

<p>This is a very common optimizer that balances exploding and vanishing</p>
<h2 class="mume-header" id="hidden-units">Hidden Units</h2>

<p>Hidden units are the dimensions of the projections the layers map the input data onto.  Think of each hidden unit as more freedom you&apos;re giving the model.</p>
<p><strong>More hidden units</strong> means <strong>more variance</strong> - overfitting, and <strong>less bias</strong>.  You need to strike a nice balance here!</p>
<p>Note that the hidden units represent the <em>columns of the weight matrix</em>, <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi></mrow><annotation encoding="application/x-tex">W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">W</span></span></span></span></p>
<p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>W</mi></mrow><annotation encoding="application/x-tex">W</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.68333em;vertical-align:0em;"></span><span class="mord mathdefault" style="margin-right:0.13889em;">W</span></span></span></span>&apos;s shape is therefore <code>(input_dimensions, hidden_units)</code></p>
<h1 class="mume-header" id="activations">Activations</h1>

<p><img src="https://qph.fs.quoracdn.net/main-qimg-07bc0ec05532caf5ebe8b4c82d0f5ca3" alt="Activation Functions"></p>
<blockquote>
<p>Without an activation function like relu (also called a non-linearity), the Dense layer would consist of two linear operations&#x2014;a dot product and an addition. So  the  layer  could  only  learn  linear  transformations  (affine  transformations)  of  the input data: the hypothesis space of the layer would be the set of all possible lineartransformations of the input data into a 16-dimensional space. Such a hypothesisspace is too restricted</p>
</blockquote>
<h2 class="mume-header" id="relu">relu</h2>

<p><code>relu</code> stands for Rectified Linear Unit, and it is a function meant to zero out negative values.</p>
<h2 class="mume-header" id="sigmoid">sigmoid</h2>

<p>This allows us to use probability distributions by squashing are values down into the interval [0, 1].</p>
<h1 class="mume-header" id="notebooks">Notebooks</h1>

<ol>
<li><a href="http://localhost:8888/notebooks/categories/MLProjects/Notes/Keras-IMDB.ipynb">First neural network with Keras</a></li>
<li></li>
</ol>




</div>


</div>        </div>        <footer>                    <script src="https://cdnjs.cloudflare.com/ajax/libs/tocbot/4.11.1/tocbot.min.js"></script>            <script>tocbot.init({                                       tocSelector: '.toc',                                        contentSelector: '.content',                                        headingSelector: 'h1, h2, h3',                                       hasInnerContainers: true,                    base: (window.location.pathname + window.location.search)                });</script>            <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src="https://code.jquery.com/jquery-3.5.1.min.js" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>            <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous">                </script><script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha384-B4gt1jrGC7Jh4AgTPSdUtOBvfO8shuf57BaghqFfPlYxofvL8/KUEfYiJOMMV+rV" crossorigin="anonymous"></script><script>document.querySelector("body").setAttribute("data-spy", "scroll"); document.querySelector("body").setAttribute("data-target","#toc");</script>            <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">                </script><script type="text/javascript" src="/scripts/main.js" < script>
      </div>
      
      
    </body>
    
    
    
    
    
    
    
  </html>
    </script></footer></div></div></body></html>